import datetime as dt
import ee

ee.Initialize()

# ===== AOI SAU S√ÅP NH·∫¨P: HCM + B√åNH D∆Ø∆†NG + B√Ä R·ªäA-V≈®NG T√ÄU =====
# B·∫£n merge V2 b·∫°n v·ª´a export (3 t·ªânh g·ªôp l·∫°i)
AOI_MERGED = ee.FeatureCollection(
    "users/tranleanhdaintd2/hcm_merged_v2"
).geometry()

# ===== AOI RI√äNG T·ª™NG T·ªàNH (ƒë·ªÉ d√†nh, sau n√†y t√°ch th·ªëng k√™) =====
AOI_HCM = ee.FeatureCollection(
    "users/tranleanhdaintd2/hcm_only"
).geometry()

AOI_BD = ee.FeatureCollection(
    "users/tranleanhdaintd2/binhduong_only"
).geometry()

AOI_BRVT = ee.FeatureCollection(
    "users/tranleanhdaintd2/brvt_only"
).geometry()

# Bi·∫øn AOI c≈© ‚Äì gi·ªØ l·∫°i cho c√°c h√†m ph√≠a d∆∞·ªõi d√πng,
# hi·ªán t·∫°i = to√†n v√πng sau s√°p nh·∫≠p (3 t·ªânh).
AOI = AOI_MERGED


# ---------- Helpers ----------


def _to_db(img: ee.Image) -> ee.Image:
    """Chuy·ªÉn t·ª´ thang linear sang dB."""
    return ee.Image(10).multiply(img.log10())


def _lee_speckle(img_db: ee.Image) -> ee.Image:
    """L·ªçc nhi·ªÖu ƒë∆°n gi·∫£n 3x3."""
    return img_db.focal_mean(radius=1, units="pixels")


def load_s1_vv(aoi: ee.Geometry, start: str, end: str) -> ee.Image:
    """L·∫•y Sentinel-1 VV, median, l·ªçc nhi·ªÖu, tr·∫£ v·ªÅ ·∫£nh dB."""
    col = (
        ee.ImageCollection("COPERNICUS/S1_GRD")
        .filterBounds(aoi)
        .filterDate(start, end)
        .filter(ee.Filter.eq("instrumentMode", "IW"))
        .filter(ee.Filter.eq("orbitProperties_pass", "DESCENDING"))
        .filter(ee.Filter.listContains("transmitterReceiverPolarisation", "VV"))
        .select("VV")
    )

    size = col.size()
    vv_db_fallback = ee.Image.constant(-20).rename("VV").clip(aoi)

    def _compose_db(ic: ee.ImageCollection) -> ee.Image:
        vv_lin = ic.map(
            lambda i: ee.Image.constant(10).pow(i.select("VV").divide(10))
        )
        vv_med_lin = vv_lin.median()
        vv_db = _to_db(vv_med_lin).rename("VV")
        return _lee_speckle(vv_db).clip(aoi)

    vv_db = ee.Image(
        ee.Algorithms.If(size.gt(0), _compose_db(col), vv_db_fallback)
    )
    return vv_db


def jrc_perm_water_mask() -> ee.Image:
    """Mask n∆∞·ªõc th∆∞·ªùng tr·ª±c (occurrence >= 75%)."""
    return (
        ee.Image("JRC/GSW1_4/GlobalSurfaceWater")
        .select("occurrence")
        .gte(75)
    )


def srtm_elev_mask(max_m: float) -> ee.Image:
    """Mask v√πng c√≥ cao ƒë·ªô <= max_m (DEM SRTM)."""
    return ee.Image("USGS/SRTMGL1_003").lte(max_m)


def otsu_threshold(img_db: ee.Image, region: ee.Geometry, scale: int) -> ee.Number:
    """
    ·ªû ƒë√¢y d√πng percentile 10% l√†m ng∆∞·ª°ng ƒë∆°n gi·∫£n (thay cho Otsu ƒë·∫ßy ƒë·ªß).
    N·∫øu reduceRegion r·ªóng -> fallback -15 dB.
    """
    img = img_db.rename("x")

    dct = img.reduceRegion(
        reducer=ee.Reducer.percentile([10]),
        geometry=region,
        scale=scale,
        bestEffort=True,
    )

    vals = ee.Dictionary(dct).values()
    p = ee.Algorithms.If(
        ee.Number(ee.List(vals).size()).gt(0),
        ee.List(vals).get(0),
        None,
    )

    return ee.Number(ee.Algorithms.If(p, p, -15))


def _area_km2_for_region(
    flood_img: ee.Image, region: ee.Geometry, scale: int
) -> ee.Number:
    """
    T√≠nh di·ªán t√≠ch ng·∫≠p (km¬≤) trong 1 v√πng con (HCM / BD / BRVT).
    flood_img: ·∫£nh mask 0/1 ƒë√£ rename('flood').
    """
    stats_area = flood_img.multiply(ee.Image.pixelArea()).reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=region,
        scale=scale,
        maxPixels=1e13,
        bestEffort=True,
    ).get("flood")

    area_m2 = ee.Number(
        ee.Algorithms.If(stats_area, stats_area, ee.Number(0))
    )
    return area_m2.divide(1e6)


# ---------- Main flood pipeline cho 1 s·ª± ki·ªán (d√πng cho /flood) ----------


def detect_flood(
    aoi_fc,
    pre_start: str,
    pre_end: str,
    event_start: str,
    event_end: str,
    min_diff_db: float = -2.0,
    elev_max_m: float = 15,
    scale: int = 30,
):
    """
    Ph√°t hi·ªán ng·∫≠p cho 1 kho·∫£ng th·ªùi gian:
    - Lu√¥n d√πng AOI sau s√°p nh·∫≠p (AOI_MERGED = HCM + BD + BR-VT).
    - aoi_fc gi·ªØ l·∫°i ch·ªâ ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi main.py, nh∆∞ng b·ªã b·ªè qua.

    L∆ØU √ù:
    - C√°c th·ªëng k√™ area_km2, pixel_count hi·ªán t·∫°i l√†
      T·ªîNG DI·ªÜN T√çCH NG·∫¨P TO√ÄN V√ôNG SAU S√ÅP NH·∫¨P (3 t·ªânh),
      ƒë·ªìng th·ªùi c√≥ th√™m area_km2_hcm / bd / brvt.
    """

    aoi = AOI  # = AOI_MERGED

    # VV dB tr∆∞·ªõc v√† trong s·ª± ki·ªán
    pre_vv = load_s1_vv(aoi, pre_start, pre_end)
    evt_vv = load_s1_vv(aoi, event_start, event_end)

    # ch√™nh l·ªách dB
    delta = evt_vv.subtract(pre_vv)  # event - pre (dB)

    # ng∆∞·ª°ng n∆∞·ªõc t·ª´ event
    otsu = otsu_threshold(evt_vv, aoi, scale)
    water_evt = evt_vv.lte(otsu)

    # gi·∫£m dB ƒë·ªß m·∫°nh
    drop = delta.lte(min_diff_db)

    # k·∫øt h·ª£p
    flood = water_evt.And(drop)

    # b·ªè n∆∞·ªõc th∆∞·ªùng tr·ª±c + ƒë·ªãa h√¨nh cao
    flood = flood.updateMask(jrc_perm_water_mask().Not())
    if elev_max_m is not None:
        flood = flood.updateMask(srtm_elev_mask(elev_max_m))

    # ƒë·∫£m b·∫£o band name ·ªïn ƒë·ªãnh ƒë·ªÉ reduceRegion kh√¥ng null
    flood = flood.updateMask(flood).rename("flood").clip(aoi)

    # --- Th·ªëng k√™ t·ªïng (fallback 0 server-side) ---
    stats_count = flood.reduceRegion(
        reducer=ee.Reducer.count(),
        geometry=aoi,
        scale=scale,
        maxPixels=1e13,
        bestEffort=True,
    ).get("flood")
    pixel_count = ee.Number(
        ee.Algorithms.If(stats_count, stats_count, ee.Number(0))
    )

    stats_area = flood.multiply(ee.Image.pixelArea()).reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=aoi,
        scale=scale,
        maxPixels=1e13,
        bestEffort=True,
    ).get("flood")
    area_m2 = ee.Number(
        ee.Algorithms.If(stats_area, stats_area, ee.Number(0))
    )
    area_km2 = area_m2.divide(1e6)

    # --- Di·ªán t√≠ch ng·∫≠p cho t·ª´ng khu: HCM / BD / BRVT ---
    area_km2_hcm = _area_km2_for_region(flood, AOI_HCM, scale)
    area_km2_bd = _area_km2_for_region(flood, AOI_BD, scale)
    area_km2_brvt = _area_km2_for_region(flood, AOI_BRVT, scale)

    # --- Vector h√≥a ---
    vectors = flood.selfMask().reduceToVectors(
        geometry=aoi,
        scale=scale,
        maxPixels=1e13,
        geometryType="polygon",
        labelProperty="class",
        eightConnected=True,
    )
    aoi_fc = ee.FeatureCollection([ee.Feature(aoi, {})])

    # üëá TR·∫¢ TH√äM 3 ·∫¢NH pre / event / delta
    return {
        "image": flood,  # mask nh·ªã ph√¢n (0/1) cho map & t√≠nh to√°n
        "aoi": aoi,
        "pixel_count": pixel_count,
        "area_km2": area_km2,
        "area_km2_hcm": area_km2_hcm,
        "area_km2_bd": area_km2_bd,
        "area_km2_brvt": area_km2_brvt,
        "vectors": vectors,
        "aoi_fc": aoi_fc,
        "pre_vv_db": pre_vv,
        "evt_vv_db": evt_vv,
        "delta_db": delta,
        # NOTE: n·∫øu sau n√†y b·∫°n mu·ªën t√°ch theo t·ªânh,
        # c√≥ th·ªÉ d√πng AOI_HCM, AOI_BD, AOI_BRVT ·ªü ƒë√¢y.
    }


# ---------- Phi√™n b·∫£n nh·∫π cho TIMESERIES: ch·ªâ t√≠nh stats, kh√¥ng vector ----------


def detect_flood_stats_only(
    pre_start: str,
    pre_end: str,
    event_start: str,
    event_end: str,
    min_diff_db: float = -2.0,
    elev_max_m: float = 15,
    scale: int = 30,
):
    """
    Pipeline gi·ªëng detect_flood nh∆∞ng KH√îNG vector h√≥a,
    ch·ªâ tr·∫£ v·ªÅ (area_km2, pixel_count) d·∫°ng ee.Number.
    D√πng ri√™ng cho generate_flood_timeseries ƒë·ªÉ nh·∫π h∆°n.

    L∆ØU √ù: v·∫´n l√† th·ªëng k√™ TR√äN TO√ÄN V√ôNG SAU S√ÅP NH·∫¨P (3 t·ªânh).
    """
    aoi = AOI

    pre_vv = load_s1_vv(aoi, pre_start, pre_end)
    evt_vv = load_s1_vv(aoi, event_start, event_end)

    delta = evt_vv.subtract(pre_vv)
    otsu = otsu_threshold(evt_vv, aoi, scale)
    water_evt = evt_vv.lte(otsu)
    drop = delta.lte(min_diff_db)
    flood = water_evt.And(drop)

    flood = flood.updateMask(jrc_perm_water_mask().Not())
    if elev_max_m is not None:
        flood = flood.updateMask(srtm_elev_mask(elev_max_m))

    flood = flood.updateMask(flood).rename("flood").clip(aoi)

    stats_count = flood.reduceRegion(
        reducer=ee.Reducer.count(),
        geometry=aoi,
        scale=scale,
        maxPixels=1e13,
        bestEffort=True,
    ).get("flood")
    pixel_count = ee.Number(
        ee.Algorithms.If(stats_count, stats_count, ee.Number(0))
    )

    stats_area = flood.multiply(ee.Image.pixelArea()).reduceRegion(
        reducer=ee.Reducer.sum(),
        geometry=aoi,
        scale=scale,
        maxPixels=1e13,
        bestEffort=True,
    ).get("flood")
    area_m2 = ee.Number(
        ee.Algorithms.If(stats_area, stats_area, ee.Number(0))
    )
    area_km2 = area_m2.divide(1e6)

    return area_km2, pixel_count


def to_geojson(fc, max_features: int = 10000):
    """
    Chuy·ªÉn FeatureCollection sang GeoJSON, gi·ªõi h·∫°n s·ªë feature
    ƒë·ªÉ tr√°nh l·ªói 'Collection query aborted after accumulating over 5000 elements'.
    """
    fc = ee.FeatureCollection(fc).limit(max_features)
    return fc.getInfo()


# ---------- T·∫†O ·∫¢NH B·∫¢N ƒê·ªí NG·∫¨P CHO REPORT / WEBGIS ----------


def make_flood_map_image(flood_img: ee.Image, aoi: ee.Geometry) -> ee.Image:
    """
    T·∫°o ·∫£nh b·∫£n ƒë·ªì ng·∫≠p ƒë·ªÉ xu·∫•t PNG:
    - N·ªÅn t·ªëi
    - Ranh gi·ªõi AOI m√†u v√†ng
    - V√πng ng·∫≠p m√†u xanh d∆∞∆°ng

    flood_img: ·∫£nh mask 0/1 (band "flood") t·ª´ detect_flood["image"].
    """
    base = (
        ee.Image.constant([10, 10, 15])  # h∆°i x√°m m·ªôt ch√∫t
        .rename(["R", "G", "B"])
        .visualize(bands=["R", "G", "B"], min=0, max=50)
    )

    flood_vis = (
        ee.Image(flood_img)
        .selfMask()
        .visualize(min=0, max=1, palette=["00BFFF"])  # DeepSkyBlue
    )

    aoi_border = (
        ee.Image()
        .byte()
        .paint(aoi, 1, 3)
        .visualize(palette=["FFFF00"])
    )

    return base.blend(flood_vis).blend(aoi_border)


def make_vv_image(vv_db: ee.Image, aoi: ee.Geometry) -> ee.Image:
    """
    Visualize VV dB (pre ho·∫∑c event) v·ªõi thang x√°m + vi·ªÅn AOI v√†ng.
    """
    vv_vis = (
        vv_db.clip(aoi)
        .visualize(
            min=-25,
            max=0,
            palette=["000000", "333333", "888888", "FFFFFF"],
        )
    )

    aoi_border = (
        ee.Image()
        .byte()
        .paint(aoi, 1, 3)
        .visualize(palette=["FFFF00"])
    )

    return vv_vis.blend(aoi_border)


def make_delta_image(delta_db: ee.Image, aoi: ee.Geometry) -> ee.Image:
    """
    Visualize ŒîdB (event - pre) v·ªõi gi·∫£ m√†u:
    gi·∫£m m·∫°nh -> t√≠m/xanh, √≠t thay ƒë·ªïi -> v√†ng.
    """
    delta_vis = (
        delta_db.clip(aoi)
        .visualize(
            min=-5,
            max=1,
            palette=[
                "440154",  # t√≠m
                "3b528b",
                "21918c",
                "5ec962",
                "fde725",  # v√†ng
            ],
        )
    )

    aoi_border = (
        ee.Image()
        .byte()
        .paint(aoi, 1, 3)
        .visualize(palette=["FFFF00"])
    )

    return delta_vis.blend(aoi_border)


def thumb_url(img, region, size: int = 1024, is_mask: bool = True) -> str:
    """
    T·∫°o URL thumbnail:
    - N·∫øu is_mask=True  (m·∫∑c ƒë·ªãnh): img l√† mask 0/1 -> t·ª± selfMask, min/max 0‚Äì1
    - N·∫øu is_mask=False: img ƒë√£ visualize (RGB) -> d√πng tr·ª±c ti·∫øp, kh√¥ng ƒë·ªïi min/max
    """
    image = ee.Image(img)

    if is_mask:
        params = {
            "min": 0,
            "max": 1,
            "dimensions": size,
            "region": region,
            "format": "png",
        }
        image = image.selfMask()
    else:
        params = {
            "dimensions": size,
            "region": region,
            "format": "png",
        }

    return image.getThumbURL(params)


# ---------- Flood TIMESERIES (d√πng cho script precompute) ----------


def generate_flood_timeseries(
    years: int = 3,
    step_days: int = 45,
    min_diff_db: float = -2.0,
    elev_max_m: float = 15,
    scale: int = 30,
):
    """
    Sinh chu·ªói th·ªùi gian di·ªán t√≠ch ng·∫≠p.
    - M·∫∑c ƒë·ªãnh 3 nƒÉm g·∫ßn nh·∫•t, m·ªói ~45 ng√†y 1 ƒëi·ªÉm.
    - V·ªõi m·ªói m·ªëc:
        + pre: t·ª´ d-7 t·ªõi d-1
        + event: t·ª´ d t·ªõi d+2
    Tr·∫£ v·ªÅ: list c√°c dict {date, area_km2, pixel_count, ...}
    """

    today = dt.date.today()
    start = today - dt.timedelta(days=365 * years)

    dates = []
    d = start
    while d <= today:
        dates.append(d)
        d += dt.timedelta(days=step_days)

    series = []

    for d in dates:
        pre_start = (d - dt.timedelta(days=7)).isoformat()
        pre_end = (d - dt.timedelta(days=1)).isoformat()
        event_start = d.isoformat()
        event_end = (d + dt.timedelta(days=2)).isoformat()

        try:
            area_ee, pixels_ee = detect_flood_stats_only(
                pre_start=pre_start,
                pre_end=pre_end,
                event_start=event_start,
                event_end=event_end,
                min_diff_db=min_diff_db,
                elev_max_m=elev_max_m,
                scale=scale,
            )

            area_km2 = float(area_ee.getInfo())
            pixel_count = int(pixels_ee.getInfo())
        except Exception:
            continue

        series.append(
            {
                "date": d.isoformat(),
                "area_km2": area_km2,
                "pixel_count": pixel_count,
                "pre_start": pre_start,
                "pre_end": pre_end,
                "event_start": event_start,
                "event_end": event_end,
            }
        )

    return series


# ---------- RAINFALL (CHIRPS DAILY) ----------


def rainfall_timeseries(
    start_date: str,
    end_date: str,
    scale: int = 5000,
):
    """
    T√≠nh l∆∞·ª£ng m∆∞a trung b√¨nh (mm/ng√†y) tr√™n to√†n AOI
    d√πng dataset CHIRPS Daily, cho kho·∫£ng th·ªùi gian [start_date, end_date].

    Tr·∫£ v·ªÅ list c√°c dict:
    [{ "date": "YYYY-MM-DD", "rain_mm": float }, ...]
    """
    start = ee.Date(start_date)
    end = ee.Date(end_date)

    col = (
        ee.ImageCollection("UCSB-CHG/CHIRPS/DAILY")
        .filterDate(start, end)
        .filterBounds(AOI)
        .select("precipitation")
    )

    def per_image(img):
        mean_rain = img.reduceRegion(
            reducer=ee.Reducer.mean(),
            geometry=AOI,
            scale=scale,
            maxPixels=1e13,
            bestEffort=True,
        ).get("precipitation")

        date_str = img.date().format("YYYY-MM-dd")
        return ee.Feature(
            None,
            {
                "date": date_str,
                "rain_mm": mean_rain,
            },
        )

    fc = ee.FeatureCollection(col.map(per_image))

    features = fc.getInfo().get("features", [])
    data = []

    for f in features:
        props = f.get("properties", {})
        date = props.get("date")
        rain = props.get("rain_mm")
        rain_val = float(rain) if rain is not None else 0.0
        data.append({"date": date, "rain_mm": rain_val})

    return data


# ---------- FLOOD + RAIN CORRELATION (EE version ‚Äì √≠t d√πng) ----------


def _pearson_corr(xs, ys):
    """
    T√≠nh h·ªá s·ªë t∆∞∆°ng quan Pearson ƒë∆°n gi·∫£n cho 2 list s·ªë.
    Tr·∫£ v·ªÅ None n·∫øu √≠t h∆°n 2 ph·∫ßn t·ª≠ ho·∫∑c ph∆∞∆°ng sai b·∫±ng 0.
    """
    n = len(xs)
    if n < 2:
        return None

    mean_x = sum(xs) / n
    mean_y = sum(ys) / n

    var_x = sum((x - mean_x) ** 2 for x in xs)
    var_y = sum((y - mean_y) ** 2 for y in ys)
    if var_x == 0 or var_y == 0:
        return None

    cov = sum((xs[i] - mean_x) * (ys[i] - mean_y) for i in range(n))
    return cov / (var_x ** 0.5 * var_y ** 0.5)


def flood_rain_correlation(
    years: int = 5,
    step_days: int = 30,
    rainfall_scale: int = 5000,
    min_diff_db: float = -2.0,
    elev_max_m: float = 15,
    scale: int = 30,
):
    """
    PHI√äN B·∫¢N ƒê·∫¶Y ƒê·ª¶ ‚Äì t√≠nh lu√¥n chu·ªói ng·∫≠p b·∫±ng GEE (ch·∫°y n·∫∑ng).
    Gi·ªØ l·∫°i ƒë·ªÉ d√πng offline / script n·∫øu c·∫ßn, nh∆∞ng frontend kh√¥ng g·ªçi n·ªØa.
    """

    flood_series = generate_flood_timeseries(
        years=years,
        step_days=step_days,
        min_diff_db=min_diff_db,
        elev_max_m=elev_max_m,
        scale=scale,
    )

    if not flood_series:
        return {"data": [], "corr": None}

    start_date = flood_series[0]["date"]
    end_date = flood_series[-1]["date"]

    rain_series = rainfall_timeseries(
        start_date=start_date,
        end_date=end_date,
        scale=rainfall_scale,
    )

    rain_map = {r["date"]: r["rain_mm"] for r in rain_series}

    combined = []
    rains = []
    areas = []

    for f in flood_series:
        d = f["date"]
        if d in rain_map:
            rain = float(rain_map[d]) if rain_map[d] is not None else 0.0
            area = float(f["area_km2"])
            combined.append(
                {
                    "date": d,
                    "rain_mm": rain,
                    "area_km2": area,
                }
            )
            rains.append(rain)
            areas.append(area)

    corr = _pearson_corr(rains, areas) if combined else None

    return {
        "data": combined,
        "corr": corr,
    }


# ---------- FLOOD + RAIN CORRELATION (d√πng chu·ªói NG·∫¨P CACHE) ----------


def flood_rain_correlation_from_cached(
    flood_series,
    rainfall_scale: int = 5000,
):
    """
    Nh·∫≠n s·∫µn flood_series (list dict t·ª´ JSON cache),
    ch·ªâ g·ªçi CHIRPS cho m∆∞a v√† t√≠nh t∆∞∆°ng quan.

    flood_series: [{ "date": "YYYY-MM-DD", "area_km2": float, ... }, ...]
    """
    if not flood_series:
        return {"data": [], "corr": None}

    # ƒë·∫£m b·∫£o sort theo th·ªùi gian
    sorted_series = sorted(flood_series, key=lambda r: r["date"])

    # L·∫•y kho·∫£ng th·ªùi gian c·∫ßn cho CHIRPS
    dates = [dt.date.fromisoformat(rec["date"]) for rec in sorted_series]
    start_date = min(dates).isoformat()
    end_date = max(dates).isoformat()

    rain_series = rainfall_timeseries(
        start_date=start_date,
        end_date=end_date,
        scale=rainfall_scale,
    )

    rain_map = {r["date"]: r["rain_mm"] for r in rain_series}

    combined = []
    rains = []
    areas = []

    for f in sorted_series:
        d = f["date"]
        if d in rain_map:
            rain = float(rain_map[d]) if rain_map[d] is not None else 0.0
            area = float(f.get("area_km2", 0.0))
            combined.append(
                {
                    "date": d,
                    "rain_mm": rain,
                    "area_km2": area,
                }
            )
            rains.append(rain)
            areas.append(area)

    corr = _pearson_corr(rains, areas) if combined else None

    return {
        "data": combined,
        "corr": corr,
    }
